{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "313326985_206172686.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1"
      ],
      "metadata": {
        "id": "JYjt1AkdZkP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Id numbers and names\n",
        "\n",
        "\n",
        "1.   313326985 Shahar Shcheranski\n",
        "2.   206172686 Sarit Hollander"
      ],
      "metadata": {
        "id": "quyaTwTGZufW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. forward propagation process:"
      ],
      "metadata": {
        "id": "a2-UoCdB-eHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from time import time"
      ],
      "metadata": {
        "id": "69Jd_rpDHV-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5KekURS9h6m"
      },
      "outputs": [],
      "source": [
        "def initialize_parameters(layer_dims):\n",
        "    \"\"\"\n",
        "\n",
        "    :param layer_dims: an array of the dimensions of each layer in the network\n",
        "    (layer 0 is the size of the flattened input, layer L is the output softmax\n",
        "    :return: a dictionary containing the initialized W and b parameters of each layer (W1…WL, b1…bL)\n",
        "    \"\"\"\n",
        "    parameters = {}\n",
        "    for i in range(1, len(layer_dims)):\n",
        "        parameters['W' + str(i)] = np.random.randn(layer_dims[i], layer_dims[i - 1]) * np.sqrt(2/layer_dims[i-1])\n",
        "        parameters['b' + str(i)] = np.zeros((layer_dims[i], 1))\n",
        "\n",
        "    return parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_forward(A, W, b):\n",
        "    \"\"\"\n",
        "    Implement the linear part of a layer's forward propagation\n",
        "    :param A: the activations of the previous layer\n",
        "    :param W: the weight matrix of the current layer (of shape [size of current layer, size of previous layer])\n",
        "    :param b: the bias vector of the current layer (of shape [size of current layer, 1])\n",
        "    :return: Z – the linear component of the activation function (i.e., the value before applying the non-linear function)\n",
        "    linear_cache – a dictionary containing A, W, b (stored for making the backpropagation easier to compute)\n",
        "    \"\"\"\n",
        "    Z = np.dot(W, A) + b\n",
        "    linear_cache = {'A': A, 'W': W, 'b': b}\n",
        "    \n",
        "    return Z, linear_cache"
      ],
      "metadata": {
        "id": "5Jeuxzpc2ydC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(Z):\n",
        "    \"\"\"\n",
        "    :param Z: the linear component of the activation function\n",
        "    :return: A – the activations of the layer\n",
        "    activation_cache – returns Z, which will be useful for the backpropagation\n",
        "    \"\"\"\n",
        "    z_exp = np.exp(Z)\n",
        "    A = z_exp / np.sum(z_exp, axis=0)\n",
        "    activation_cache = {'Z': Z}\n",
        "\n",
        "    return A, activation_cache"
      ],
      "metadata": {
        "id": "O5v3bkwz9mhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "    \"\"\"\n",
        "    :param Z: the linear component of the activation function\n",
        "    :return: A – the activations of the layer\n",
        "    activation_cache – returns Z, which will be useful for the backpropagation\n",
        "    \"\"\"\n",
        "    def relu_return_max(z):\n",
        "        return np.maximum(0., z)\n",
        "\n",
        "    activation_cache = {'Z': Z}\n",
        "    relu_return_max = np.vectorize(relu_return_max)\n",
        "    A = relu_return_max(Z)\n",
        "    \n",
        "    return A, activation_cache"
      ],
      "metadata": {
        "id": "LV5ihfc6Q9u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_dropout(Z,prob):\n",
        "    \"\"\"\n",
        "    :param Z: the linear component of the activation function\n",
        "    :param prob: the probability of keeping a node in each layer\n",
        "    :return: A – the activations of the layer\n",
        "    activation_cache – returns Z, D, prob, which will be useful for the backpropagation\n",
        "    \"\"\"\n",
        "\n",
        "    A, relue_cache = relu(Z)\n",
        "    A, dropout_cache = dropout(A, prob)\n",
        "    activation_cache = {**relue_cache, **dropout_cache}\n",
        "    return A, activation_cache"
      ],
      "metadata": {
        "id": "Mr9kSwelOEut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout(A, prob):\n",
        "    \"\"\"\n",
        "    :param A: the activations of the layer\n",
        "    :param prob: the probability of keeping a node in each layer\n",
        "    :return: A – the activations of the layer\n",
        "    dropout_cache – returns Z, D, prob, which will be useful for the backpropagation\n",
        "    \"\"\"\n",
        "    D = np.random.rand(A.shape[0],A.shape[1]) < prob\n",
        "    A = A*D\n",
        "    A = A/prob\n",
        "    dropout_cache = {'D': D, 'prob' : prob}\n",
        "    return A, dropout_cache"
      ],
      "metadata": {
        "id": "C2IO_vQiO0Gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_forward(A_prev, W, B, activation):\n",
        "    \"\"\"\n",
        "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
        "    :param A_prev: activations of the previous layer\n",
        "    :param W: the weights matrix of the current layer\n",
        "    :param B: the bias vector of the current layer\n",
        "    :param activation: the activation function to be used (a string, either “softmax” or “relu”)\n",
        "    :return: A – the activations of the current layer\n",
        "    cache – a joint dictionary containing both linear_cache and activation_cache\n",
        "    \"\"\"\n",
        "    Z, linear_cache = linear_forward(A_prev, W, B)\n",
        "    if activation == \"softmax\":\n",
        "        A, activation_cache = softmax(Z)\n",
        "    elif activation == \"relu\":\n",
        "        if use_dropout:\n",
        "          A, activation_cache = relu_dropout(Z, prob=prob_dropout)\n",
        "        else:\n",
        "          A, activation_cache = relu(Z)\n",
        "\n",
        "\n",
        "    cache = {**linear_cache, **activation_cache}\n",
        "\n",
        "    return A, cache"
      ],
      "metadata": {
        "id": "QCg75qndyk4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_forward(X, parameters, use_batchnorm):\n",
        "    \"\"\"\n",
        "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SOFTMAX\n",
        "    :param X: the data, numpy array of shape (input size, number of examples)\n",
        "    :param parameters: the initialized W and b parameters of each layer\n",
        "    :param use_batchnorm: - a boolean flag used to determine whether to apply batchnorm after the activation\n",
        "    (note that this option needs to be set to “false” in Section 3 and “true” in Section 4).\n",
        "    :return: AL – the last post-activation value\n",
        "    caches – a list of all the cache objects generated by the linear_forward function\n",
        "    \"\"\"\n",
        "    layers = len(parameters) // 2\n",
        "    A_prev = X\n",
        "    caches = []\n",
        "\n",
        "    for i in range(1, layers):\n",
        "        W = parameters['W' + str(i)]\n",
        "        b = parameters['b' + str(i)]\n",
        "        A, cache = linear_activation_forward(A_prev, W, b, 'relu')\n",
        "        caches.append(cache)\n",
        "        if use_batchnorm:\n",
        "            A = apply_batchnorm(A)\n",
        "\n",
        "        A_prev = A\n",
        "\n",
        "    W = parameters['W' + str(layers)]\n",
        "    b = parameters['b' + str(layers)]\n",
        "    AL, cache = linear_activation_forward(A_prev, W, b, 'softmax')\n",
        "    caches.append(cache)\n",
        "\n",
        "    return AL, caches"
      ],
      "metadata": {
        "id": "1Ygt8uXhRYrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y):\n",
        "    \"\"\"\n",
        "    Implement the cost function defined by equation. The requested cost function is categorical cross-entropy loss.\n",
        "    :param AL: probability vector corresponding to your label predictions, shape (num_of_classes, number of examples)\n",
        "    :param Y: the labels vector (i.e. the ground truth)\n",
        "    :return: cost – the cross-entropy cost\n",
        "    \"\"\"\n",
        "    m = AL.shape[1]\n",
        "    cost = -(1/m) * np.sum(Y * np.log(AL))\n",
        "    return cost"
      ],
      "metadata": {
        "id": "AEdzwb5BRcZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_batchnorm(A):\n",
        "    \"\"\"\n",
        "    performs batchnorm on the received activation values of a given layer.\n",
        "    :param A: the activation values of a given layer\n",
        "    :return: NA - the normalized activation values, based on the formula learned in class\n",
        "    \"\"\"\n",
        "    mu = np.mean(A, axis=1, keepdims=True)\n",
        "    eps = 0.00000001\n",
        "    var = np.var(A, axis=1, keepdims=True)\n",
        "    NA = (A - mu) / np.sqrt(var + eps)\n",
        "\n",
        "    return NA"
      ],
      "metadata": {
        "id": "Vll6_lI3ReFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. backward propagation process"
      ],
      "metadata": {
        "id": "sYC13hyMZW3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Linear_backward(dZ, cache):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Implements the linear part of the backward propagation process for a single layer\n",
        "\n",
        "  Inputs:\n",
        "    dZ - the gradient of the cost with respect to the linear output of the current layer (layer l)\n",
        "    cache - tuple of values (A_prev, W, b) coming from the forward propagation in the current layer \n",
        "\n",
        "  Output: \n",
        "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "  \"\"\"\n",
        "\n",
        "  A_prev = cache['A']\n",
        "  W = cache['W']\n",
        "  b = cache['b']\n",
        "\n",
        "  m = A_prev.shape[1]\n",
        "\n",
        "  dA_prev = np.dot(W.T, dZ)\n",
        "  dW = np.dot(dZ, A_prev.T)/m\n",
        "  db = np.sum(dZ, axis=1, keepdims=True)/m\n",
        "\n",
        "  return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "jsA9YgQXZdSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "  \"\"\" \n",
        "  Description:\n",
        "    Implements the backward propagation for the LINEAR->ACTIVATION layer. The function first computes dZ and then applies the linear_backward function.\n",
        "\n",
        "  Input:\n",
        "    dA – post activation gradient of the current layer\n",
        "    cache – contains both the linear cache and the activations cache\n",
        "\n",
        "  Output:\n",
        "    dA_prev – Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
        "    dW – Gradient of the cost with respect to W (current layer l), same shape as W\n",
        "    db – Gradient of the cost with respect to b (current layer l), same shape as b\n",
        "  \"\"\"\n",
        "\n",
        "  if activation == 'relu':\n",
        "    if use_dropout:\n",
        "      dZ = relu_dropout_backward(dA, cache)\n",
        "    else:\n",
        "      dZ = relu_backward(dA, cache)\n",
        "  elif activation == 'softmax':\n",
        "      dZ = softmax_backward(dA, cache)\n",
        "\n",
        "  dA_prev, dW, db = Linear_backward(dZ, cache)\n",
        "\n",
        "  return dA_prev, dW, db"
      ],
      "metadata": {
        "id": "dAikVqWCczp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_backward (dA, activation_cache):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Implements backward propagation for a ReLU unit\n",
        "\n",
        "  Input:\n",
        "    dA – the post-activation gradient\n",
        "    activation_cache – contains Z (stored during the forward propagation)\n",
        "\n",
        "  Output:\n",
        "    dZ – gradient of the cost with respect to Z\n",
        "  \"\"\"\n",
        "  \n",
        "  Z = activation_cache['Z']\n",
        "\n",
        "  dZ = dA\n",
        "  dZ[Z < 0] = 0\n",
        "\n",
        "  return dZ\n"
      ],
      "metadata": {
        "id": "ewmS4jlkdET_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_dropout_backward(dA, activation_cache):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Implements backward propagation for a dropout ReLU unit\n",
        "\n",
        "  Input:\n",
        "    dA – the post-activation gradient\n",
        "    activation_cache – contains Z (stored during the forward propagation)\n",
        "\n",
        "  Output:\n",
        "    dZ – gradient of the cost with respect to Z\n",
        "  \"\"\"\n",
        "\n",
        "  dA = dropout_backward(dA, activation_cache)\n",
        "  dZ = relu_backward (dA, activation_cache)\n",
        "\n",
        "  return dZ\n"
      ],
      "metadata": {
        "id": "VoZBxSwvOrvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_backward (dA, activation_cache):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Implements backward propagation for a softmax unit\n",
        "\n",
        "  Input:\n",
        "    dA – the post-activation gradient\n",
        "    activation_cache – contains: \n",
        "      Z (stored during the forward propagation)\n",
        "      AL - the probabilities vector, the output of the forward propagation (L_model_forward)\n",
        "      Y - the true labels vector (the \"ground truth\" - true classifications)\n",
        "\n",
        "  Output:\n",
        "    dZ – gradient of the cost with respect to Z\n",
        "  \"\"\"\n",
        "\n",
        "  Z = activation_cache['Z']\n",
        "  AL = activation_cache['AL']\n",
        "  Y = activation_cache['Y']\n",
        "\n",
        "  dZ = AL - Y\n",
        "\n",
        "  return dZ\n"
      ],
      "metadata": {
        "id": "kKWLRiwEdOUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_backward(dA, dropout_cache):\n",
        "\n",
        "  D = dropout_cache['D']\n",
        "  prob = dropout_cache['prob']\n",
        "\n",
        "  dA = dA*D\n",
        "  dA = dA/prob\n",
        "\n",
        "  return dA\n"
      ],
      "metadata": {
        "id": "YeCxuji6P9T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Implement the backward propagation process for the entire network.\n",
        "\n",
        "  Input:\n",
        "    AL - the probabilities vector, the output of the forward propagation (L_model_forward)\n",
        "    Y - the true labels vector (the \"ground truth\" - true classifications)\n",
        "    Caches - list of caches containing for each layer: a) the linear cache; b) the activation cache\n",
        "\n",
        "  Output:\n",
        "    Grads - a dictionary with the gradients\n",
        "             grads[\"dA\" + str(l)] = ... \n",
        "             grads[\"dW\" + str(l)] = ...\n",
        "             grads[\"db\" + str(l)] = ...\n",
        "  \"\"\"\n",
        "    \n",
        "  layers = len(caches)\n",
        "  grads = {}\n",
        "\n",
        "  # Initializing the backpropagation\n",
        "  dAL = - (Y/AL) + (1 - Y)/(1 - AL)\n",
        "\n",
        "  # Lth layer (ACTIVATION -> LINEAR) gradients. \n",
        "  current_cache = caches[layers - 1]\n",
        "  current_cache['AL'] = AL\n",
        "  current_cache['Y'] = Y\n",
        "  grads['dA' + str(layers)], grads['dW' + str(layers)], grads['db' + str(layers)] = linear_activation_backward(dAL, current_cache, activation = 'softmax')\n",
        "\n",
        "  for i in range(layers - 1, 0, -1):\n",
        "      previous_layer = i + 1\n",
        "      curreny_layer = i\n",
        "      current_cache = caches[i - 1]\n",
        "      grads['dA' + str(curreny_layer)], grads['dW' + str(curreny_layer)], grads['db' + str(curreny_layer)] = linear_activation_backward(grads['dA' + str(previous_layer)], current_cache, activation = 'relu')\n",
        "\n",
        "  return grads\n",
        "\n"
      ],
      "metadata": {
        "id": "9nlsKYzgdZUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Update_parameters(parameters, grads, learning_rate):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Updates parameters using gradient descent\n",
        "\n",
        "  Input:\n",
        "    parameters – a python dictionary containing the DNN architecture’s parameters\n",
        "    grads – a python dictionary containing the gradients (generated by L_model_backward)\n",
        "    learning_rate – the learning rate used to update the parameters (the “alpha”)\n",
        "\n",
        "  Output:\n",
        "    parameters – the updated values of the parameters object provided as input\n",
        "  \"\"\"\n",
        "\n",
        "  layers = len(parameters) // 2\n",
        "\n",
        "  for i in range(1, layers + 1):\n",
        "    parameters['W' + str(i)] = parameters['W' + str(i)] - (learning_rate * grads['dW' + str(i)])\n",
        "    parameters['b' + str(i)] = parameters['b' + str(i)] - (learning_rate * grads['db' + str(i)])\n",
        "                                                           \n",
        "  return parameters"
      ],
      "metadata": {
        "id": "tVwcc8O7dlKU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. train the network and produce predictions"
      ],
      "metadata": {
        "id": "Hs6AlxqWytxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "6HrUViQdElPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# global parameters\n",
        "use_batchnorm = False\n",
        "stopping_rate = 0.001\n",
        "splitting_factor = 0.2\n",
        "use_dropout = False\n",
        "prob_dropout = 0.8"
      ],
      "metadata": {
        "id": "oiONE2U47yRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def L_layer_model(X, Y, layers_dims, learning_rate, num_iterations, batch_size):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    Implements a L-layer neural network. All layers but the last should have the ReLU activation function, and the final layer will apply the softmax activation function. The size of the output layer should be equal to the number of labels in the data. Please select a batch size that enables your code to run well (i.e. no memory overflows while still running relatively fast).\n",
        "\n",
        "    Hint: the function should use the earlier functions in the following order: initialize -> L_model_forward -> compute_cost -> L_model_backward -> update parameters\n",
        "\n",
        "  Input:\n",
        "    X – the input data, a numpy array of shape (height*width , number_of_examples) \n",
        "    Comment: since the input is in grayscale we only have height and width, otherwise it would have been height*width*3\n",
        "    Y – the “real” labels of the data, a vector of shape (num_of_classes, number of examples)\n",
        "    Layer_dims – a list containing the dimensions of each layer, including the input\n",
        "    batch_size – the number of examples in a single training batch.\n",
        "\n",
        "  Output:\n",
        "    parameters – the parameters learnt by the system during the training (the same parameters that were updated in the update_parameters function).\n",
        "    costs – the values of the cost function (calculated by the compute_cost function). One value is to be saved after each 100 training iterations (e.g. 3000 iterations -> 30 values)\n",
        "  \"\"\"\n",
        "  num_of_classes = Y.shape[0]\n",
        "  data = np.concatenate([X, Y], axis=0)\n",
        "  np.random.shuffle(data.T)\n",
        "  samples = int(splitting_factor * data.shape[1])\n",
        "  train = data[:, samples:]\n",
        "  x_train, y_train = train[:-num_of_classes, :], train[-num_of_classes:, :]\n",
        "  test = data[:, :samples]\n",
        "  x_test, y_test = test[:-num_of_classes, :], test[-num_of_classes:, :]\n",
        "\n",
        "  data = np.concatenate([x_train, y_train], axis=0)\n",
        "  number_of_examples = x_train.shape[1]\n",
        "\n",
        "  num_of_batches = math.ceil(number_of_examples / batch_size)\n",
        "\n",
        "  parameters = initialize_parameters(layers_dims)\n",
        "  costs = []\n",
        "\n",
        "  iter = 0\n",
        "  while len(costs) < 2 or np.abs(costs[-2] - costs[-1]) > stopping_rate:\n",
        "      if iter % num_of_batches == 0:\n",
        "          np.random.shuffle(data.T)\n",
        "          all_batches = np.array_split(data, indices_or_sections=num_of_batches, axis=1)\n",
        "      batch_divided = iter % num_of_batches\n",
        "      curr_x_batch = all_batches[batch_divided][0:x_train.shape[0], :]\n",
        "      curr_y_batch = all_batches[batch_divided][x_train.shape[0]:, :]\n",
        "\n",
        "      AL, caches = L_model_forward(curr_x_batch, parameters,use_batchnorm=use_batchnorm)\n",
        "      grads = L_model_backward(AL, curr_y_batch, caches)\n",
        "      parameters = Update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "      iter += 1\n",
        "\n",
        "      if iter % num_iterations == 0:\n",
        "          AL = L_model_forward(x_test, parameters,use_batchnorm=use_batchnorm)[0]\n",
        "          cost = compute_cost(AL, y_test)\n",
        "          costs.append(cost)\n",
        "          print('Iteration number: ' + str(iter) + ', cost: ' + str(cost))\n",
        "\n",
        "  if iter % num_of_batches == 0:\n",
        "        print('iterated on ' + str(iter // num_of_batches) + ' epochs')\n",
        "  else:\n",
        "        print('iterated on ' + str(iter // num_of_batches) + ' epochs and ' + str(iter % num_of_batches) + ' iterations')\n",
        "\n",
        "  train_accuracy = Predict(X=x_train, Y=y_train, parameters=parameters) * 100\n",
        "  test_accuracy = Predict(X=x_test, Y=y_test, parameters=parameters) * 100\n",
        "\n",
        "  print('Train accuracy: ' + str(train_accuracy) + '%')\n",
        "  print('Validation accuracy: ' + str(test_accuracy) + '%')\n",
        "\n",
        "  return parameters, costs"
      ],
      "metadata": {
        "id": "xZ2EhJFuyw2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict(X, Y, parameters):\n",
        "  \"\"\"\n",
        "  Description:\n",
        "    The function receives an input data and the true labels and calculates the accuracy of the trained neural network on the data.\n",
        "\n",
        "  Input:\n",
        "    X – the input data, a numpy array of shape (height*width, number_of_examples)\n",
        "    Y – the “real” labels of the data, a vector of shape (num_of_classes, number of examples)\n",
        "    Parameters – a python dictionary containing the DNN architecture’s parameters\n",
        "\n",
        "  Output:\n",
        "    accuracy – the accuracy measure of the neural net on the provided data (i.e. the percentage of the samples for which the correct label receives the hughest confidence score). Use the softmax function to normalize the output values.\n",
        "  \"\"\"\n",
        "  number_of_examples = X.shape[1]\n",
        "\n",
        "  AL, caches = L_model_forward(X, parameters, use_batchnorm)\n",
        "\n",
        "  y_pred = np.argmax(AL, axis=0)\n",
        "  y_true = np.argmax(Y, axis=0)\n",
        "\n",
        "  correct = np.sum(y_pred == y_true)\n",
        "\n",
        "  return correct/number_of_examples\n"
      ],
      "metadata": {
        "id": "f8gicYu3zVLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. classify the MNIST dataset"
      ],
      "metadata": {
        "id": "Z5Oon-IDPZf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a.\tLoad the dataset using the Keras code"
      ],
      "metadata": {
        "id": "xwGr85MZPn_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that there is a predefined division between the train and test set. Use 20% of the training set as a validation set (samples need to be randomly chosen)."
      ],
      "metadata": {
        "id": "geUVy0asXrLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "mCmzIYHWQwy2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13a209bb-ece7-4d96-f2f3-0fbaabe434c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The input at each iteration needs to be “flattened” to a matrix of [m,784] where m is the number of samples\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1]*x_train.shape[2])\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1]*x_test.shape[2]) "
      ],
      "metadata": {
        "id": "Qif6kvKWyABD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the labeles into one-hot encoded matrix\n",
        "\n",
        "one_hot_train = np.zeros((y_train.size, 10))\n",
        "one_hot_train[np.arange(y_train.size), y_train] = 1\n",
        "\n",
        "y_train = one_hot_train\n",
        "\n",
        "one_hot_test = np.zeros((y_test.size, 10))\n",
        "one_hot_test[np.arange(y_test.size), y_test] = 1\n",
        "\n",
        "y_test = one_hot_test"
      ],
      "metadata": {
        "id": "Xt8ApBObzMVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize\n",
        "\n",
        "x_train = x_train/255\n",
        "x_test = x_test/255"
      ],
      "metadata": {
        "id": "hCmAo1m64rI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b.\tRun your network"
      ],
      "metadata": {
        "id": "3LyegeVvXwLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "using the following configuration:\n",
        "*   4 layers (aside from the input layer), with the following sizes: 20,7,5,10\n",
        "*   Do not activate the batchnorm option at this point\n",
        "*   The input at each iteration needs to be “flattened” to a matrix of [m,784]  where m is the number of samples\n",
        "*   Use a learning rate of 0.009\n",
        "*   Train the network until there is no improvement on the validation set (or the improvement is very small) for 100 training steps (this is the stopping criterion). Please include in the report the number of iterations and epochs needed to train your network. Also, specify the batch size."
      ],
      "metadata": {
        "id": "yXzXHycfP2yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "start_time = time()\n",
        "params, costs = L_layer_model(X=x_train.T, Y=y_train.T, layers_dims=[784,20,7,5,10],learning_rate=0.009, num_iterations=100, batch_size=256)\n",
        "end_time = time()"
      ],
      "metadata": {
        "id": "EVP_garWPkEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031f660f-c3b2-4759-d89f-003534ebe9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration number: 100, cost: 2.140946214501379\n",
            "Iteration number: 200, cost: 1.9282392544680587\n",
            "Iteration number: 300, cost: 1.8262511902216816\n",
            "Iteration number: 400, cost: 1.7443139537360717\n",
            "Iteration number: 500, cost: 1.6697881141018145\n",
            "Iteration number: 600, cost: 1.6033084415963446\n",
            "Iteration number: 700, cost: 1.541559816856163\n",
            "Iteration number: 800, cost: 1.4824780348323399\n",
            "Iteration number: 900, cost: 1.4259559134060302\n",
            "Iteration number: 1000, cost: 1.362867431396588\n",
            "Iteration number: 1100, cost: 1.3004780078546945\n",
            "Iteration number: 1200, cost: 1.2395499622190367\n",
            "Iteration number: 1300, cost: 1.1817233768434643\n",
            "Iteration number: 1400, cost: 1.1337055897849624\n",
            "Iteration number: 1500, cost: 1.0875369181915069\n",
            "Iteration number: 1600, cost: 1.047555406162395\n",
            "Iteration number: 1700, cost: 1.0111468431220292\n",
            "Iteration number: 1800, cost: 0.9785508219333166\n",
            "Iteration number: 1900, cost: 0.9458758377839221\n",
            "Iteration number: 2000, cost: 0.915823171619826\n",
            "Iteration number: 2100, cost: 0.8881098958037275\n",
            "Iteration number: 2200, cost: 0.8622339483350229\n",
            "Iteration number: 2300, cost: 0.8359291959613631\n",
            "Iteration number: 2400, cost: 0.814507678164633\n",
            "Iteration number: 2500, cost: 0.7895218309460448\n",
            "Iteration number: 2600, cost: 0.7696193435413166\n",
            "Iteration number: 2700, cost: 0.7497697632674469\n",
            "Iteration number: 2800, cost: 0.7306862941652141\n",
            "Iteration number: 2900, cost: 0.7131150659282312\n",
            "Iteration number: 3000, cost: 0.6968269874137512\n",
            "Iteration number: 3100, cost: 0.67975896609376\n",
            "Iteration number: 3200, cost: 0.6687962742888642\n",
            "Iteration number: 3300, cost: 0.650652735925788\n",
            "Iteration number: 3400, cost: 0.6365928445101074\n",
            "Iteration number: 3500, cost: 0.6233928740454108\n",
            "Iteration number: 3600, cost: 0.6099372628954749\n",
            "Iteration number: 3700, cost: 0.596479591508238\n",
            "Iteration number: 3800, cost: 0.5870624584140866\n",
            "Iteration number: 3900, cost: 0.5753461054067305\n",
            "Iteration number: 4000, cost: 0.5629096685775207\n",
            "Iteration number: 4100, cost: 0.551938145449247\n",
            "Iteration number: 4200, cost: 0.541514294789849\n",
            "Iteration number: 4300, cost: 0.5343991426162341\n",
            "Iteration number: 4400, cost: 0.5244493116814352\n",
            "Iteration number: 4500, cost: 0.5173031618784693\n",
            "Iteration number: 4600, cost: 0.5070486289296179\n",
            "Iteration number: 4700, cost: 0.49974422240475586\n",
            "Iteration number: 4800, cost: 0.49198507160400207\n",
            "Iteration number: 4900, cost: 0.48423376653197214\n",
            "Iteration number: 5000, cost: 0.4780934979601695\n",
            "Iteration number: 5100, cost: 0.47153027651236523\n",
            "Iteration number: 5200, cost: 0.4651456680461357\n",
            "Iteration number: 5300, cost: 0.45962693932142845\n",
            "Iteration number: 5400, cost: 0.4525108433532482\n",
            "Iteration number: 5500, cost: 0.4465930333862986\n",
            "Iteration number: 5600, cost: 0.4425093683918676\n",
            "Iteration number: 5700, cost: 0.4390967053724533\n",
            "Iteration number: 5800, cost: 0.4311777086449862\n",
            "Iteration number: 5900, cost: 0.4292353802350941\n",
            "Iteration number: 6000, cost: 0.4224796028107828\n",
            "Iteration number: 6100, cost: 0.41918243085703094\n",
            "Iteration number: 6200, cost: 0.4151820054506626\n",
            "Iteration number: 6300, cost: 0.4105078575130202\n",
            "Iteration number: 6400, cost: 0.4057179597426831\n",
            "Iteration number: 6500, cost: 0.4027647399106966\n",
            "Iteration number: 6600, cost: 0.39879185177602505\n",
            "Iteration number: 6700, cost: 0.3965269198446305\n",
            "Iteration number: 6800, cost: 0.39152069015754143\n",
            "Iteration number: 6900, cost: 0.3885366742618927\n",
            "Iteration number: 7000, cost: 0.3881308507047243\n",
            "iterated on 37 epochs and 44 iterations\n",
            "Train accuracy: 90.95625000000001%\n",
            "Validation accuracy: 90.46666666666667%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy: '+ str(Predict(X=x_test.T, Y=y_test.T, parameters=params) * 100) + '%')\n",
        "print('Running Time: ' + str(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxTSr83xGAUk",
        "outputId": "8211ff03-620c-4a9a-b8b4-1cf56262f96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 90.49000000000001%\n",
            "Running Time: 228.07242965698242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot costs\n",
        "plt.plot(costs)\n",
        "plt.title('Validation Costs')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Cost')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "3KxHEpaQwCuA",
        "outputId": "4b36f6e3-6e37-49c6-91a4-5a2d8a5f41f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Cost')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Repeat section 4 when the batchnorm function is “on”"
      ],
      "metadata": {
        "id": "uDNltoVGoXl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze and compare this experiment to the previous one (performance, running time, number of training steps etc.). There is no need to update the parameters of the batchnorm in the way described in the lecture."
      ],
      "metadata": {
        "id": "pymxIw9VYetk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_batchnorm = True"
      ],
      "metadata": {
        "id": "3DcEH9eTgWJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "start_time = time()\n",
        "params, costs = L_layer_model(X=x_train.T, Y=y_train.T, layers_dims=[784,20,7,5,10],learning_rate=0.009, num_iterations=100, batch_size=256)\n",
        "end_time = time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfs5zzIfo_qI",
        "outputId": "ca521642-53f6-4549-d46d-4b3e71676060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration number: 100, cost: 2.2012278531596743\n",
            "Iteration number: 200, cost: 1.9723635312106331\n",
            "Iteration number: 300, cost: 1.8562567317757954\n",
            "Iteration number: 400, cost: 1.7840242202723242\n",
            "Iteration number: 500, cost: 1.7265812033319434\n",
            "Iteration number: 600, cost: 1.6805266338522304\n",
            "Iteration number: 700, cost: 1.6355338111530555\n",
            "Iteration number: 800, cost: 1.597995272916762\n",
            "Iteration number: 900, cost: 1.562978667214431\n",
            "Iteration number: 1000, cost: 1.5185826871161359\n",
            "Iteration number: 1100, cost: 1.478213410015933\n",
            "Iteration number: 1200, cost: 1.4383942774564014\n",
            "Iteration number: 1300, cost: 1.4005104012056933\n",
            "Iteration number: 1400, cost: 1.3646312815725588\n",
            "Iteration number: 1500, cost: 1.3270451529345477\n",
            "Iteration number: 1600, cost: 1.2957736602322956\n",
            "Iteration number: 1700, cost: 1.2652590521421385\n",
            "Iteration number: 1800, cost: 1.2335901961084477\n",
            "Iteration number: 1900, cost: 1.204258592515176\n",
            "Iteration number: 2000, cost: 1.1807007113964378\n",
            "Iteration number: 2100, cost: 1.1563338836673205\n",
            "Iteration number: 2200, cost: 1.1343392553255076\n",
            "Iteration number: 2300, cost: 1.1140604042047595\n",
            "Iteration number: 2400, cost: 1.093955091918993\n",
            "Iteration number: 2500, cost: 1.0786855698865534\n",
            "Iteration number: 2600, cost: 1.0604497077878923\n",
            "Iteration number: 2700, cost: 1.04545940221494\n",
            "Iteration number: 2800, cost: 1.0312857399880124\n",
            "Iteration number: 2900, cost: 1.0208278113024847\n",
            "Iteration number: 3000, cost: 1.0063859711051766\n",
            "Iteration number: 3100, cost: 0.9941363789256503\n",
            "Iteration number: 3200, cost: 0.9780565578083633\n",
            "Iteration number: 3300, cost: 0.9627516915382034\n",
            "Iteration number: 3400, cost: 0.9452052271117289\n",
            "Iteration number: 3500, cost: 0.9295311780232713\n",
            "Iteration number: 3600, cost: 0.9171890340532217\n",
            "Iteration number: 3700, cost: 0.9119773443935209\n",
            "Iteration number: 3800, cost: 0.8929551422485389\n",
            "Iteration number: 3900, cost: 0.875887449474503\n",
            "Iteration number: 4000, cost: 0.8622328577098374\n",
            "Iteration number: 4100, cost: 0.8446294724402273\n",
            "Iteration number: 4200, cost: 0.8332054210715893\n",
            "Iteration number: 4300, cost: 0.8228644182485908\n",
            "Iteration number: 4400, cost: 0.8134084663334508\n",
            "Iteration number: 4500, cost: 0.8022432831215597\n",
            "Iteration number: 4600, cost: 0.7918295230286037\n",
            "Iteration number: 4700, cost: 0.7826486971136384\n",
            "Iteration number: 4800, cost: 0.7745731043449683\n",
            "Iteration number: 4900, cost: 0.767005367456855\n",
            "Iteration number: 5000, cost: 0.7552441918740863\n",
            "Iteration number: 5100, cost: 0.748073319647438\n",
            "Iteration number: 5200, cost: 0.7389631282248197\n",
            "Iteration number: 5300, cost: 0.7312392140476976\n",
            "Iteration number: 5400, cost: 0.721227339680446\n",
            "Iteration number: 5500, cost: 0.7133637332320453\n",
            "Iteration number: 5600, cost: 0.7042378881358987\n",
            "Iteration number: 5700, cost: 0.7020284468020062\n",
            "Iteration number: 5800, cost: 0.6912958405619333\n",
            "Iteration number: 5900, cost: 0.6858977919024235\n",
            "Iteration number: 6000, cost: 0.6767139173321106\n",
            "Iteration number: 6100, cost: 0.6678564541489809\n",
            "Iteration number: 6200, cost: 0.6608686178985014\n",
            "Iteration number: 6300, cost: 0.6526403287689498\n",
            "Iteration number: 6400, cost: 0.647112951626875\n",
            "Iteration number: 6500, cost: 0.6423062081241517\n",
            "Iteration number: 6600, cost: 0.6310260157114729\n",
            "Iteration number: 6700, cost: 0.629455166423961\n",
            "Iteration number: 6800, cost: 0.62198538883232\n",
            "Iteration number: 6900, cost: 0.6103820464776165\n",
            "Iteration number: 7000, cost: 0.607281554237909\n",
            "Iteration number: 7100, cost: 0.5990747394272798\n",
            "Iteration number: 7200, cost: 0.5939245214536027\n",
            "Iteration number: 7300, cost: 0.5896299448934709\n",
            "Iteration number: 7400, cost: 0.5818873197887843\n",
            "Iteration number: 7500, cost: 0.575909353142628\n",
            "Iteration number: 7600, cost: 0.5701044951253618\n",
            "Iteration number: 7700, cost: 0.5651291051354217\n",
            "Iteration number: 7800, cost: 0.5562866061351669\n",
            "Iteration number: 7900, cost: 0.5476540975575569\n",
            "Iteration number: 8000, cost: 0.542663947733778\n",
            "Iteration number: 8100, cost: 0.5355782166248453\n",
            "Iteration number: 8200, cost: 0.5332134804887978\n",
            "Iteration number: 8300, cost: 0.5243086176674367\n",
            "Iteration number: 8400, cost: 0.5181606358200853\n",
            "Iteration number: 8500, cost: 0.511222212434174\n",
            "Iteration number: 8600, cost: 0.5073660610944509\n",
            "Iteration number: 8700, cost: 0.5027584781448433\n",
            "Iteration number: 8800, cost: 0.4984837889460663\n",
            "Iteration number: 8900, cost: 0.4922983652412116\n",
            "Iteration number: 9000, cost: 0.48657160431764185\n",
            "Iteration number: 9100, cost: 0.48377381021774235\n",
            "Iteration number: 9200, cost: 0.47790399744734\n",
            "Iteration number: 9300, cost: 0.47467413489595983\n",
            "Iteration number: 9400, cost: 0.47352674797224503\n",
            "Iteration number: 9500, cost: 0.4683434152263779\n",
            "Iteration number: 9600, cost: 0.4632670765363427\n",
            "Iteration number: 9700, cost: 0.4638403642984444\n",
            "iterated on 51 epochs and 112 iterations\n",
            "Train accuracy: 89.57083333333333%\n",
            "Validation accuracy: 88.84166666666667%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy: '+ str(Predict(X=x_test.T, Y=y_test.T, parameters=params) * 100) + '%')\n",
        "print('Running Time: ' + str(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXBgeQiWpC7C",
        "outputId": "a9066f14-c62e-4881-9646-2cccf0d7631b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 89.13%\n",
            "Running Time: 326.4042909145355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot costs\n",
        "plt.plot(costs)\n",
        "plt.title('Validation Costs')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Cost')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "NAcGHAZfz3z7",
        "outputId": "583b9bbf-8913-470c-e9c0-b613484c47ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Cost')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Bonus"
      ],
      "metadata": {
        "id": "AqR5I6ruXQsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_batchnorm = False\n",
        "use_dropout = True"
      ],
      "metadata": {
        "id": "-9zsXaCKgayZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10)\n",
        "\n",
        "start_time = time()\n",
        "params, costs = L_layer_model(X=x_train.T, Y=y_train.T, layers_dims=[784,20,7,5,10],learning_rate=0.009, num_iterations=100, batch_size=256)\n",
        "end_time = time()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH4DUJb9ZH8Q",
        "outputId": "a0db0b42-e6f1-4d42-a276-45b9000742d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration number: 100, cost: 2.246695790756403\n",
            "Iteration number: 200, cost: 2.1435621090139314\n",
            "Iteration number: 300, cost: 2.081946471816097\n",
            "Iteration number: 400, cost: 2.038807944302734\n",
            "Iteration number: 500, cost: 2.0014975743742096\n",
            "Iteration number: 600, cost: 1.973300636006961\n",
            "Iteration number: 700, cost: 1.9595073146223945\n",
            "Iteration number: 800, cost: 1.9261571135035236\n",
            "Iteration number: 900, cost: 1.9105179394538454\n",
            "Iteration number: 1000, cost: 1.8958746284904997\n",
            "Iteration number: 1100, cost: 1.8751713563876031\n",
            "Iteration number: 1200, cost: 1.8494006635671685\n",
            "Iteration number: 1300, cost: 1.8456589255726739\n",
            "Iteration number: 1400, cost: 1.8338710894658998\n",
            "Iteration number: 1500, cost: 1.8075060605401043\n",
            "Iteration number: 1600, cost: 1.8029754517043186\n",
            "Iteration number: 1700, cost: 1.7934663895122078\n",
            "Iteration number: 1800, cost: 1.7804894354446301\n",
            "Iteration number: 1900, cost: 1.7628209553653589\n",
            "Iteration number: 2000, cost: 1.7554717542428135\n",
            "Iteration number: 2100, cost: 1.7493505516038197\n",
            "Iteration number: 2200, cost: 1.7360211333934858\n",
            "Iteration number: 2300, cost: 1.7264396325023879\n",
            "Iteration number: 2400, cost: 1.7004943912971515\n",
            "Iteration number: 2500, cost: 1.705074275368438\n",
            "Iteration number: 2600, cost: 1.6957354293412905\n",
            "Iteration number: 2700, cost: 1.6809834925110863\n",
            "Iteration number: 2800, cost: 1.6808382820515049\n",
            "iterated on 14 epochs and 168 iterations\n",
            "Train accuracy: 40.5625%\n",
            "Validation accuracy: 40.733333333333334%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test accuracy: '+ str(Predict(X=x_test.T, Y=y_test.T, parameters=params) * 100) + '%')\n",
        "print('Running Time: ' + str(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs0LyDx1ZKRq",
        "outputId": "4b2d8fc1-b599-4f8a-b8f4-3081cc7c26cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 40.68%\n",
            "Running Time: 95.6027467250824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot costs\n",
        "plt.plot(costs)\n",
        "plt.title('Validation Costs')\n",
        "plt.xlabel('Training Steps')\n",
        "plt.ylabel('Cost')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "pFA7M0y63BOO",
        "outputId": "e8991904-ef3e-43f9-eda6-cb2cecb0011e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Cost')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}